{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandas.core.indexing import _IndexSlice\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.core.dtypes.common import is_numeric_dtype\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "idx: _IndexSlice = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data\n",
    "DATA_PATH = Path(\"data/01_known_effects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of samples\n",
    "samples = pd.read_csv(\n",
    "    DATA_PATH / \"experiments.csv\",\n",
    "    index_col=0,\n",
    "    decimal=\",\"\n",
    "    )\n",
    "\n",
    "# Create an index from the experiment table\n",
    "samples_index_fields = {\n",
    "        'Label': \"label\",\n",
    "        'Effect in PSET':\"effect\",\n",
    "        'Treatment': \"treatment\",\n",
    "        'Experimenter, location': \"experimenter_location\",\n",
    "        'Strain': \"strain\",\n",
    "        'CO2 level': \"CO2_level\",\n",
    "        'Cultivation + experiment temperature': \"temperature\",\n",
    "        'Cultivation light intensity': \"Light_intensity\",\n",
    "        'Dark or light acclimated': \"light_acclimation\",\n",
    "        'Growth light color (nm)': \"light_color\",\n",
    "        'Cultivator': \"cultivator\",\n",
    "        'Medium': \"medium\",\n",
    "        'Fluorometer': \"fluorometer\",\n",
    "        'SP color (nm)': \"SP_color\",\n",
    "        'SP intensity': \"SP_intensity\",\n",
    "        'Measuring vessel': \"vessel\",\n",
    "        'OD680 MC-1000': \"OD680\",\n",
    "        'OD720 MC-1000': \"OD720\",\n",
    "        'Î”OD': \"deltaOD\",\n",
    "        'OD680/720 raw': \"OD680_720\",\n",
    "}\n",
    "samples_index_fields_inv = {v:k for k,v in samples_index_fields.items()}\n",
    "\n",
    "samples_index = pd.MultiIndex.from_frame(\n",
    "    samples.reset_index().loc[:, list(samples_index_fields.keys())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_levels(df, level):\n",
    "    columns = df.columns.remove_unused_levels()\n",
    "    \n",
    "    # Get the levels and the index corresponding to the level\n",
    "    _level = samples_index_fields_inv[level]\n",
    "    level_ind = np.where(np.array(list(df.columns.names)) == _level)[0][0]\n",
    "    return list(columns.levels[level_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "fig, axes = plt.subplots(\n",
    "    int(np.ceil(len(samples.columns[2:])/3)), \n",
    "    3,\n",
    "    figsize = (7, 15)\n",
    ")\n",
    "\n",
    "for column, ax in zip(samples.columns[2:], axes.flatten()):\n",
    "    # Get the values dor each column and count the occurrences\n",
    "    dat = samples.loc[:,column]\n",
    "    if not is_numeric_dtype(dat.dtype):\n",
    "        dat = dat.value_counts()\n",
    "        dat.plot(kind=\"bar\", ax=ax)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=10, ha='right')\n",
    "    else:\n",
    "        dat.plot(kind=\"hist\", ax=ax)\n",
    "\n",
    "    ax.set_title(column, size=10)\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "fig.subplots_adjust(\n",
    "    wspace = 0.3,\n",
    "    hspace=0.7\n",
    ")\n",
    "\n",
    "for column in samples.columns[:2]:\n",
    "    fig, ax = plt.subplots()\n",
    "    dat = samples.loc[:,column]\n",
    "    dat = dat.value_counts()\n",
    "    dat.plot(kind=\"bar\", ax=ax)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    ax.set_title(column, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in samples_index_fields.values():\n",
    "#     print(f\"{i},\")# : str | list[str | int] | slice | None = slice(None),\")\n",
    "\n",
    "# Create a function for easy indexing\n",
    "def didx(\n",
    "    label: str | list[str | int] | slice | None = slice(None),\n",
    "    effect: str | list[str | int] | slice | None = slice(None),\n",
    "    treatment: str | list[str | int] | slice | None = slice(None),\n",
    "    experimenter_location: str | list[str | int] | slice | None = slice(None),\n",
    "    strain: str | list[str | int] | slice | None = slice(None),\n",
    "    CO2_level: str | list[str | int] | slice | None = slice(None),\n",
    "    temperature: str | list[str | int] | slice | None = slice(None),\n",
    "    Light_intensity: str | list[str | int] | slice | None = slice(None),\n",
    "    light_acclimation: str | list[str | int] | slice | None = slice(None),\n",
    "    light_color: str | list[str | int] | slice | None = slice(None),\n",
    "    cultivator: str | list[str | int] | slice | None = slice(None),\n",
    "    medium: str | list[str | int] | slice | None = slice(None),\n",
    "    fluorometer: str | list[str | int] | slice | None = slice(None),\n",
    "    SP_color: str | list[str | int] | slice | None = slice(None),\n",
    "    SP_intensity: str | list[str | int] | slice | None = slice(None),\n",
    "    vessel: str | list[str | int] | slice | None = slice(None),\n",
    "    OD680: str | list[str | int] | slice | None = slice(None),\n",
    "    OD720: str | list[str | int] | slice | None = slice(None),\n",
    "    deltaOD: str | list[str | int] | slice | None = slice(None),\n",
    "    OD680_720: str | list[str | int] | slice | None = slice(None),\n",
    ") -> int | str | slice:\n",
    "    res: list[str | list[str | int] | slice | None] = [\n",
    "        x\n",
    "        for x in [\n",
    "            label,\n",
    "            effect,\n",
    "            treatment,\n",
    "            experimenter_location,\n",
    "            strain,\n",
    "            CO2_level,\n",
    "            temperature,\n",
    "            Light_intensity,\n",
    "            light_acclimation,\n",
    "            light_color,\n",
    "            cultivator,\n",
    "            medium,\n",
    "            fluorometer,\n",
    "            SP_color,\n",
    "            SP_intensity,\n",
    "            vessel,\n",
    "            OD680,\n",
    "            OD720,\n",
    "            deltaOD,\n",
    "            OD680_720,\n",
    "        ]\n",
    "        if x is not None\n",
    "    ]\n",
    "    return idx[*res]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the paths to the samples files\n",
    "files = {}\n",
    "\n",
    "for i in samples_index.get_level_values(0):\n",
    "    _index = f\"{i:04}\"\n",
    "\n",
    "    # Get the file to the current index\n",
    "    file = list(DATA_PATH.glob(f\"ojip_data/{_index}*\"))[0]\n",
    "\n",
    "    # Set the options for reading the data based on the used fluorometer\n",
    "    if samples.loc[i, \"Fluorometer\"] == \"MULTI-COLOR-PAM\":\n",
    "        skiprows = 0\n",
    "        skipfooter = 0\n",
    "        sep=\";\"\n",
    "        index_col=0\n",
    "        select_col = \"Fluo, V\"\n",
    "        time_to_ms = 1\n",
    "    elif samples.loc[i, \"Fluorometer\"] == \"AquaPen\":\n",
    "        skiprows = 7\n",
    "        skipfooter = 38\n",
    "        sep=r\"\\s\"\n",
    "        index_col=0\n",
    "        select_col = \"OJIP\"\n",
    "        time_to_ms = 1e-3\n",
    "    else:\n",
    "        print(i, samples.loc[i, \"Fluorometer\"])\n",
    "        break\n",
    "\n",
    "    # Read the data with the pre-defined options\n",
    "    _df = pd.read_table(\n",
    "        file,\n",
    "        skiprows=skiprows,\n",
    "        skipfooter=skipfooter,\n",
    "        sep=sep,\n",
    "        index_col=index_col,\n",
    "        engine='c' if skipfooter == 0 else 'python'\n",
    "    )[select_col]\n",
    "\n",
    "    _df.index = pd.Index(np.round(_df.index * time_to_ms, 2))\n",
    "\n",
    "    # Save the data\n",
    "    files[i] = _df\n",
    "\n",
    "# Concatenate the data\n",
    "df = pd.DataFrame(files).sort_index(axis=1)\n",
    "df.columns = samples_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scaling factors from the fluorometer comparison data\n",
    "SCALING_DATA_PATH = Path(\"data/00_fluorometer_data_scaling\")\n",
    "\n",
    "scaling_samples = pd.read_csv(\n",
    "    SCALING_DATA_PATH / \"experiments.csv\",\n",
    "    index_col=0,\n",
    "    decimal=\",\"\n",
    "    )\n",
    "\n",
    "# Get the paths to the samples files\n",
    "files = {}\n",
    "\n",
    "for i in scaling_samples.index:\n",
    "    _index = f\"{i:02}\"\n",
    "\n",
    "    # Get the file to the current index\n",
    "    file = list(SCALING_DATA_PATH.glob(f\"ojip_data/{_index}*\"))[0]\n",
    "\n",
    "    # Set the options for reading the data based on the used fluorometer\n",
    "    if scaling_samples.loc[i, \"Fluorometer\"] == \"MULTI-COLOR-PAM\":\n",
    "        skiprows = 0\n",
    "        skipfooter = 0\n",
    "        sep=\";\"\n",
    "        index_col=0\n",
    "        select_col = \"Fluo, V\"\n",
    "        time_to_ms = 1\n",
    "    elif scaling_samples.loc[i, \"Fluorometer\"] == \"AquaPen\":\n",
    "        skiprows = 7\n",
    "        skipfooter = 38\n",
    "        sep=r\"\\s\"\n",
    "        index_col=0\n",
    "        select_col = \"OJIP\"\n",
    "        time_to_ms = 1e-3\n",
    "    else:\n",
    "        print(i, scaling_samples.loc[i, \"Fluorometer\"])\n",
    "        break\n",
    "\n",
    "    # Read the data with the pre-defined options\n",
    "    _df = pd.read_table(\n",
    "        file,\n",
    "        skiprows=skiprows,\n",
    "        skipfooter=skipfooter,\n",
    "        sep=sep,\n",
    "        index_col=index_col,\n",
    "        engine='c' if skipfooter == 0 else 'python'\n",
    "    )[select_col]\n",
    "\n",
    "    _df.index = pd.Index(np.round(_df.index * time_to_ms, 2))\n",
    "\n",
    "    # Save the data\n",
    "    files[i] = _df\n",
    "\n",
    "# Concatenate the data\n",
    "scaling_df = pd.DataFrame(files).sort_index(axis=1)\n",
    "scaling_df.columns = pd.MultiIndex.from_frame(scaling_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine scaling factors between devices \n",
    "factors = pd.DataFrame(index=pd.MultiIndex([[],[],[],[]], [[],[],[],[]], name=[\"from\", \"from SP (nm)\", \"to\", \"to SP (nm)\"]))\n",
    "\n",
    "for hue in scaling_df.columns.levels[-1]:\n",
    "    _dat = scaling_df.loc[:,idx[:,:,:,hue]].loc[0:0.05].mean().droplevel([0,-1])\n",
    "    MCPAM = _dat.loc[idx[[\"MULTI-COLOR-PAM\"], :]]\n",
    "    AQPEN = _dat.loc[idx[[\"AquaPen\"], :]]\n",
    "    \n",
    "    factors.loc[idx[*AQPEN.index[0], *MCPAM.index[0]], \"F0\"] = (\n",
    "        MCPAM.iloc[0] / AQPEN.iloc[0]\n",
    "    )\n",
    "\n",
    "# factors[\"Fm\"] = (\n",
    "#     scaling_df.loc[:, idx[:, \"MULTI-COLOR-PAM\",:]].max().droplevel([0,1,2])\n",
    "#     / scaling_df.loc[:, idx[:, \"AquaPen\",:]].max().droplevel([0,1,2])\n",
    "# )\n",
    "\n",
    "# factors = pd.DataFrame(factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine scaling factors between devices at F0 and FM\n",
    "factors = pd.DataFrame(index=pd.MultiIndex([[],[],[],[]], [[],[],[],[]], name=[\"from\", \"from SP (nm)\", \"to\", \"to SP (nm)\"]))\n",
    "\n",
    "for hue in scaling_df.columns.levels[-1]:\n",
    "    MCPAM = scaling_df.loc[:,idx[:,\"MULTI-COLOR-PAM\",:,hue]].droplevel([0,-1], axis=1)\n",
    "    AQPEN = scaling_df.loc[:,idx[:,\"AquaPen\",:,hue]].droplevel([0,-1], axis=1)\n",
    "    \n",
    "    # F0\n",
    "    factors.loc[idx[*AQPEN.columns[0], *MCPAM.columns[0]], \"F0\"] = (\n",
    "        MCPAM.loc[0:0.05].mean().iloc[0] / AQPEN.loc[0:0.05].mean().iloc[0]\n",
    "    )\n",
    "\n",
    "    # FM\n",
    "    factors.loc[idx[*AQPEN.columns[0], *MCPAM.columns[0]], \"FM\"] = (\n",
    "        MCPAM.max().iloc[0] / AQPEN.max().iloc[0]\n",
    "    )\n",
    "\n",
    "factors[\"mean\"] = factors.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale AquaPen samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale AquaPen samples with the determined conversion factors\n",
    "for (fluorometer, SP_color, _, _), factor in factors[\"mean\"].items():\n",
    "    try:\n",
    "        _df = df.loc[:, didx(fluorometer=fluorometer, SP_color=SP_color)]\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_index_levels(df, \"SP_color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, didx(\n",
    "    fluorometer=\"MULTI-COLOR-PAM\",\n",
    "    CO2_level=\"Air\", \n",
    "    strain=\"Chlorella vulgaris\",\n",
    "    # SP_color=455\n",
    ")].columns.get_level_values(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plots\n",
    "\n",
    "ax = df.loc[:, didx(\n",
    "    fluorometer=\"MULTI-COLOR-PAM\",\n",
    "    CO2_level=\"Air\", \n",
    "    strain=\"Chlorella vulgaris\",\n",
    "    # SP_color=455\n",
    ")].dropna().plot(legend=False)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Time [ms]\")\n",
    "ax.set_ylabel(\"Fluorescence [Detector V]\")\n",
    "ax.set_title(\"MCPAM - Example\")\n",
    "\n",
    "ax = df.loc[:, didx(fluorometer=\"AquaPen\", CO2_level=\"Air\")].dropna().plot(legend=False)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Time [ms]\")\n",
    "ax.set_ylabel(\"Fluorescence [AU]\")\n",
    "ax.set_title(\"AquaPen - Example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Feature selection\n",
    "Exclude AquaPen data until a conversion is found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tran2024, nine features were extracted:\n",
    "- F0\n",
    "- Fm\n",
    "- F(50 Âµs)\n",
    "- F(100 Âµs)\n",
    "- F(300 Âµs)\n",
    "- F(2 ms)\n",
    "- F(30 ms)\n",
    "- Timing of Fm\n",
    "- Area above the curve between F0 and Fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the data to the samples and time to be included in the analysis \n",
    "dat = df.loc[\n",
    "    0.01:, # Exclude data before the light pulse\n",
    "    didx(\n",
    "        fluorometer=\"MULTI-COLOR-PAM\",\n",
    "        strain='Synechocystis sp. PCC 6803',\n",
    "    )\n",
    "].dropna()\n",
    "ax = dat.plot(legend=False)\n",
    "\n",
    "for t in [0.05, 0.1, 0.3, 2, 30]:\n",
    "    ax.axvline(t)\n",
    "\n",
    "ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential other features:\n",
    "- Log-spaced subsampling\n",
    "- Timing of inflection points (I, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature table\n",
    "df_features = pd.DataFrame(index=dat.columns, columns=pd.MultiIndex([[],[]], [[],[]], dtype=[str, float]))\n",
    "\n",
    "# F0 [AU]\n",
    "df_features.loc[:, idx[\"F0 [AU]\", np.nan]] = dat.iloc[:3].mean()\n",
    "\n",
    "# Fm [AU]\n",
    "df_features.loc[:, idx[\"Fm [AU]\", np.nan]] = dat.max()\n",
    "\n",
    "# Fm timing [ms]\n",
    "df_features.loc[:, idx[\"Fm time [ms]\", np.nan]] = dat.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time points, logspaced\n",
    "time_points = np.logspace(\n",
    "    np.log10(dat.index[0]),\n",
    "    np.log10(dat.index[-1]),\n",
    "    10\n",
    ")[1:-1]\n",
    "\n",
    "# Pre-populate the interp function\n",
    "_interp = partial(np.interp, time_points, dat.index)\n",
    "\n",
    "# Interpolate the selected points\n",
    "F_sampled = dat.apply(_interp)\n",
    "F_sampled.index = pd.MultiIndex.from_product([[\"Fsampled\"], time_points])\n",
    "\n",
    "# Add sampled points to features\n",
    "df_features = pd.concat([df_features, F_sampled.T], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed for UMAP\n",
    "UMAP_seed = 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "df_features_scaled = StandardScaler().fit_transform(df_features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the UMAP embedding\n",
    "reducer = umap.UMAP(random_state=UMAP_seed)\n",
    "embedding = pd.DataFrame(\n",
    "    reducer.fit_transform(df_features_scaled),\n",
    "    index=df_features.index,\n",
    "    columns=[\"UMAP_1\", \"UMAP_2\"]\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "categories = df.columns.names[1:]\n",
    "fig, axes = plt.subplots(\n",
    "    int(np.ceil(len(categories)/3)),\n",
    "    3,\n",
    "    figsize=(7,15),\n",
    "    sharey=True,\n",
    "    sharex=True,\n",
    ")\n",
    "\n",
    "for category, ax in zip(categories, axes.flatten()):\n",
    "    sns.scatterplot(\n",
    "        embedding,\n",
    "        x=\"UMAP_1\",\n",
    "        y=\"UMAP_2\",\n",
    "        hue=category,\n",
    "        ax=ax,\n",
    "        legend=False\n",
    "    )\n",
    "    ax.set_title(category)\n",
    "\n",
    "    if len(embedding[category].value_counts()) == 1:\n",
    "        ax.text(s=\"one category\",x=0.98, y=0.98, ha=\"right\", va=\"top\", transform=ax.transAxes, size=7)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot single\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.scatterplot(\n",
    "    embedding,\n",
    "    x=\"UMAP_1\",\n",
    "    y=\"UMAP_2\",\n",
    "    hue=\"Effect in PSET\",\n",
    "    ax=ax,\n",
    ")\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = sorted(list(set([tuple(x) for x in samples[[\"Effect in PSET\", \"Treatment\"]].values])))\n",
    "\n",
    "# for x in test:\n",
    "#     print(f\"{x[0]}\\t{x[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effects_map = pd.read_csv(\n",
    "    DATA_PATH / \"effects_map.csv\",\n",
    "    header=[0,1],\n",
    "    index_col=[0,1],\n",
    "    ).fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the effects and map the mto the targets\n",
    "effects = samples.loc[df_features.index.get_level_values(0), [\"Effect in PSET\", \"Treatment\"]]\n",
    "\n",
    "df_targets = effects_map.loc[pd.MultiIndex.from_frame(effects)]\n",
    "df_targets.index = effects.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add UMAP to targets\n",
    "embedding_targets = pd.concat([\n",
    "    df_targets.droplevel(-1, axis=1),\n",
    "    embedding.set_index(\"Label\").loc[:, [\"UMAP_1\", \"UMAP_2\"]],\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "categories = effects_map.columns.get_level_values(0)\n",
    "fig, axes = plt.subplots(\n",
    "    int(np.ceil(len(categories)/3)),\n",
    "    3,\n",
    "    figsize=(7,7),\n",
    "    sharex=True,\n",
    "    sharey=True\n",
    ")\n",
    "\n",
    "for category, ax in zip(categories, axes.flatten()):\n",
    "    sns.scatterplot(\n",
    "        embedding_targets,\n",
    "        x=\"UMAP_1\",\n",
    "        y=\"UMAP_2\",\n",
    "        hue=category,\n",
    "        ax=ax,\n",
    "        legend=False\n",
    "    )\n",
    "    ax.set_title(category)\n",
    "\n",
    "    if len(embedding_targets[category].value_counts()) == 1:\n",
    "        ax.text(s=\"one category\",x=0.98, y=0.98, ha=\"right\", va=\"top\", transform=ax.transAxes, size=7)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    df_features.astype(int),\n",
    "    df_targets.astype(int), \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Scale data\n",
    "scaler_X = StandardScaler().fit(X_train.values)\n",
    "scaler_Y = StandardScaler().fit(Y_train.values)\n",
    "\n",
    "X_train_scaled = scaler_X.transform(X_train.values)\n",
    "X_test_scaled = scaler_X.transform(X_test.values)\n",
    "\n",
    "Y_train_scaled = scaler_Y.transform(Y_train.values)\n",
    "Y_test_scaled = scaler_Y.transform(Y_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input((X_train_scaled.shape[1],)),\n",
    "    Dense(64, activation='relu'),  # Input layer\n",
    "    Dense(64, activation='relu'),  # Hidden layer\n",
    "    Dense(Y_train_scaled.shape[1])  # Output layer with no activation (for regression)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])  # MSE for regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    Y_train_scaled, \n",
    "    validation_data=(X_test_scaled, Y_test_scaled),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=0,\n",
    "    callbacks=[TqdmCallback(verbose=1)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "loss, mae = model.evaluate(X_test_scaled, Y_test_scaled, verbose=0)\n",
    "print(f\"Mean Absolute Error on Test Set: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "Y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Reverse scale\n",
    "Y_pred = pd.DataFrame(\n",
    "    scaler_Y.inverse_transform(Y_pred_scaled),\n",
    "    index=X_test.index,\n",
    "    columns=Y_test.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = Y_pred.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_pred.index.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_Y_pred = Y_pred.droplevel(list(range(1,20))) \n",
    "(\n",
    "    (_Y_pred - Y_test)\n",
    "    .plot(\n",
    "        subplots=True,\n",
    "        marker=\"o\",\n",
    "        figsize=(7,15),\n",
    "        sharey=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ojipml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
